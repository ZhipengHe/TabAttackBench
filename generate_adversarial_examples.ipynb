{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Generate adversarial examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzhipeng-he\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import os\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"generate_adversarial_examples.ipynb\"\n",
    "wandb.login()\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from models import run_pytorch\n",
    "from data import get_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import foolbox\n",
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "import eagerpy as ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(adv_numpy, sample_numpy, adv_numpy_cont, train_mean, train_cov_matrix, threshold, std):\n",
    "\n",
    "    def _calculate_mahalanobis_distance(x, mean, cov_matrix):\n",
    "        # Calculate the Mahalanobis distance\n",
    "        diff = x - mean\n",
    "        inv_cov_matrix = np.linalg.inv(cov_matrix)\n",
    "        md = np.sqrt(np.dot(np.dot(diff, inv_cov_matrix), diff.T))\n",
    "        return md[0, 0] # return a scalar\n",
    "    \n",
    "    eps = 1e-8\n",
    "\n",
    "    # sparsity\n",
    "    l0_distance = np.count_nonzero(adv_numpy - sample_numpy)\n",
    "\n",
    "    # proximity\n",
    "    l1_distance = np.linalg.norm(adv_numpy - sample_numpy, ord=1)\n",
    "    l2_distance = np.linalg.norm(adv_numpy - sample_numpy, ord=2)\n",
    "    linf_distance = np.linalg.norm(adv_numpy - sample_numpy, ord=np.inf)\n",
    "\n",
    "    # deviation\n",
    "    if adv_numpy_cont is not None:\n",
    "        md = _calculate_mahalanobis_distance(adv_numpy_cont, train_mean, train_cov_matrix)\n",
    "        # Check if the Mahalanobis distance exceeds the threshold\n",
    "        is_outlier = md > threshold\n",
    "    else:\n",
    "        md = 0\n",
    "        is_outlier = 0\n",
    "\n",
    "    # sensitivity: \n",
    "    if l0_distance == 0:\n",
    "        sens = 0\n",
    "    else:\n",
    "        sens = (l1_distance / ((std + eps) * l0_distance)).mean()\n",
    "\n",
    "    return {\n",
    "        \"L0 Distance\": l0_distance,\n",
    "        \"L1 Distance\": l1_distance,\n",
    "        \"L2 Distance\": l2_distance,\n",
    "        \"Linf Distance\": linf_distance,\n",
    "        \"Mahalanobis Distance\": md,\n",
    "        \"Is Outlier\": is_outlier,\n",
    "        \"Sensitivity\": sens,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTACK_LIST = {\n",
    "    \"L2CarliniWagner\": foolbox.attacks.L2CarliniWagnerAttack(binary_search_steps=10, steps=10, stepsize=0.1),\n",
    "    \"L2DeepFool\": foolbox.attacks.L2DeepFoolAttack(),\n",
    "    \"LinfFGSM\": foolbox.attacks.LinfFastGradientAttack(),\n",
    "    \"LinfPGD\": foolbox.attacks.LinfProjectedGradientDescentAttack(),\n",
    "    \"LinfBIM\": foolbox.attacks.LinfBasicIterativeAttack(),\n",
    "    \"L2Gaussian\": foolbox.attacks.L2AdditiveGaussianNoiseAttack(),\n",
    "    \"L2Uniform\": foolbox.attacks.L2AdditiveUniformNoiseAttack(),\n",
    "    \"LinfUniform\": foolbox.attacks.LinfAdditiveUniformNoiseAttack(),\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_datapoints_as_npy(alg_name, model_name, dataset_name, epsilon, datapoints):\n",
    "\n",
    "    path = f\"./datapoints/{alg_name}_{dataset_name}/{model_name}\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    for k in datapoints.keys():\n",
    "            with open(f\"{path}/{alg_name}_{dataset_name}_{model_name}_{epsilon}_{k}_arr.npy\", 'wb') as f:\n",
    "                np.save(f, datapoints[k][\"arr\"])\n",
    "            with open(f\"{path}/{alg_name}_{dataset_name}_{model_name}_{epsilon}_{k}_arr_adv.npy\", 'wb') as f:\n",
    "                np.save(f, datapoints[k][\"arr_adv\"])\n",
    "    \n",
    "    path_set = {\n",
    "        \"success_arr\": f\"{path}/{alg_name}_{dataset_name}_{model_name}_{epsilon}_success_arr.npy\",\n",
    "        \"success_arr_adv\": f\"{path}/{alg_name}_{dataset_name}_{model_name}_{epsilon}_success_arr_adv.npy\",\n",
    "        \"arr\": f\"{path}/{alg_name}_{dataset_name}_{model_name}_{epsilon}_arr.npy\",\n",
    "        \"arr_adv\": f\"{path}/{alg_name}_{dataset_name}_{model_name}_{epsilon}_arr_adv.npy\",\n",
    "    }\n",
    "\n",
    "    return path_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_attack(model, attack_name, epsilons, X_test_tensor, y_test_tensor, X_train_tensor, num_continues, config, device):\n",
    "    # Create a Foolbox model wrapper for the PyTorch model\n",
    "    fmodel = foolbox.models.PyTorchModel(model, bounds=(0, 1))\n",
    "\n",
    "    # Create an attack object (FGSM in this case)\n",
    "    attack = ATTACK_LIST[attack_name]\n",
    "\n",
    "\n",
    "    # Generate an adversarial example\n",
    "\n",
    "    attack_success_rates = []\n",
    "    average_distances = {\n",
    "        \"L0 Distance\": [], \"L1 Distance\": [], \"L2 Distance\": [], \"Linf Distance\": [], \"Mahalanobis Distance\": [], \"Sensitivity\": []\n",
    "    }\n",
    "    outliner_rates = []\n",
    "    path_sets = []\n",
    "\n",
    "    X_train_numpy = X_train_tensor.numpy()\n",
    "\n",
    "    if num_continues != 0:\n",
    "        # for calculating mahalanobis distance, use numerical features only\n",
    "        X_train_numpy_continues = X_train_tensor[:,:num_continues].numpy()\n",
    "        train_mean = np.mean(X_train_numpy_continues, axis=0)\n",
    "        train_cov_matrix = np.cov(X_train_numpy_continues.T)\n",
    "\n",
    "        # Calculate the critical value for the Mahalanobis distance using chi-squared distribution\n",
    "        alpha = 0.05\n",
    "        degrees_of_freedom = len(train_mean)\n",
    "        # Calculate the Chi-Square critical value at the given alpha and df\n",
    "        chi_square_critical_value  = chi2.ppf(1 - alpha, df=degrees_of_freedom)\n",
    "        threshold = np.sqrt(chi_square_critical_value)\n",
    "        print(f\"Threshold: {threshold}\")\n",
    "    else:\n",
    "        X_train_numpy_continues = None\n",
    "        train_mean = None\n",
    "        train_cov_matrix = None\n",
    "        threshold = None\n",
    "        print(\"No numerical features, cannot calculate Mahalanobis distance\")\n",
    "    \n",
    "    std = np.std(X_train_numpy, axis=0)\n",
    "    # print(f\"std: {std}\")\n",
    "\n",
    "\n",
    "\n",
    "    for epsilon in epsilons:\n",
    "        # Initialize variables to keep track of success and the number of samples\n",
    "        total_samples = len(X_test_tensor)\n",
    "        successful_attacks = 0\n",
    "        total_metrics = {\n",
    "            \"L0 Distance\": 0.0, \"L1 Distance\": 0.0, \"L2 Distance\": 0.0,\n",
    "            \"Linf Distance\": 0.0, \"Mahalanobis Distance\": 0.0,\n",
    "            \"Is Outlier\": 0, \"Sensitivity\": 0.0\n",
    "        }\n",
    "\n",
    "        arr_list=[]\n",
    "        arr_list_adv=[]\n",
    "\n",
    "        success_arr_list=[]\n",
    "        success_arr_list_adv=[]\n",
    "\n",
    "        for sample_idx in tqdm(range(total_samples)):\n",
    "            sample = X_test_tensor[sample_idx].to(device).unsqueeze(0)\n",
    "            label = y_test_tensor[sample_idx].to(device).unsqueeze(0)\n",
    "\n",
    "            _, advs, success = attack(fmodel, sample, label, epsilons=[epsilon])\n",
    "\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                test_outputs = model(sample)\n",
    "                adv_outputs = model(advs[0])\n",
    "                _, predicted_classes = test_outputs.max(dim=1)\n",
    "                _, adv_predicted_classes = adv_outputs.max(dim=1)\n",
    "\n",
    "            adv_numpy = advs[0].cpu().numpy()\n",
    "            # print(adv_numpy.shape)\n",
    "            sample_numpy = sample.cpu().numpy()\n",
    "            sample_numpy_cont = adv_numpy[:,:num_continues]\n",
    "            # print(sample_numpy_cont.shape)\n",
    "\n",
    "            metrics_dict = metrics(adv_numpy, sample_numpy, sample_numpy_cont, train_mean, train_cov_matrix, threshold, std)\n",
    "\n",
    "            arr_list.append(sample_numpy)\n",
    "            arr_list_adv.append(adv_numpy)\n",
    "\n",
    "            if success:\n",
    "                successful_attacks += 1\n",
    "\n",
    "                for key, value in metrics_dict.items():\n",
    "                    total_metrics[key] += value\n",
    "\n",
    "                success_arr_list.append(sample_numpy)\n",
    "                success_arr_list_adv.append(adv_numpy)\n",
    "\n",
    "            # print(f\"Epsilon = {epsilon}, Predicted class: {predicted_classes} | Adversarial example: {adv_predicted_classes} | Success: {success} | L2 distance: {np.linalg.norm(advs[0].cpu().numpy() - sample.cpu().numpy())}\")\n",
    "\n",
    "        arr = np.concatenate(arr_list, axis=0)\n",
    "        arr_adv = np.concatenate(arr_list_adv, axis=0)\n",
    "        success_arr = np.concatenate(success_arr_list, axis=0)\n",
    "        success_arr_adv = np.concatenate(success_arr_list_adv, axis=0)\n",
    "\n",
    "        datapoints = {\n",
    "            \"all\": {\n",
    "                \"arr\": arr,\n",
    "                \"arr_adv\": arr_adv,\n",
    "            },\n",
    "            \"success\": {\n",
    "                \"arr\": success_arr,\n",
    "                \"arr_adv\": success_arr_adv,\n",
    "            }\n",
    "        }\n",
    "\n",
    "        path_set = save_datapoints_as_npy(attack_name, config[\"model\"], config[\"dataset\"], epsilon, datapoints)\n",
    "\n",
    "        if successful_attacks > 0:\n",
    "            success_rate = successful_attacks / total_samples\n",
    "            outliner_rate = total_metrics[\"Is Outlier\"] / successful_attacks\n",
    "            for key, value in total_metrics.items():\n",
    "                if key in average_distances:\n",
    "                    average_distances[key].append(value / successful_attacks)\n",
    "\n",
    "        else:\n",
    "            success_rate = 0.0\n",
    "            outliner_rate = 0.0\n",
    "            for key, value in total_metrics.items():\n",
    "                if key in average_distances:\n",
    "                    average_distances[key].append(0.0)\n",
    "        \n",
    "        attack_success_rates.append(success_rate)\n",
    "        outliner_rates.append(outliner_rate)\n",
    "        path_sets.append(path_set)\n",
    "        \n",
    "        print(f\"Epsilon = {epsilon}\")\n",
    "        print(f\"Success Rate: {success_rate * 100}%\")\n",
    "        for key, value in average_distances.items():\n",
    "            print(f\"Average {key} for Successful Attacks: {value[-1]}\")\n",
    "        print(f\"Outlier Rate for Successful Attacks: {outliner_rate * 100}%\\n\")\n",
    "        print(\"\")\n",
    "\n",
    "    return attack_success_rates, average_distances, outliner_rates, path_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_run = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Only for Testing\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# # device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "# for dataset_name in [\"Adult\"]: # \"Adult\", \"Electricity\", \"Higgs\", \"KDDCup09_appetency\", \"Mushroom\"\n",
    "#     X_train, y_train, X_val, y_val, X_test, y_test, \\\n",
    "#         X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor, X_val_tensor, y_val_tensor, \\\n",
    "#         info = get_datasets.get_split_continues(dataset_name, device)\n",
    "#     for model_name in [\"MLP\"]: # , \"TabTransformer\", \"FTTransformer\"\n",
    "#         model, train_config = run_pytorch.model_config(model_name, X_train.shape[1], 2, [], info.numerical_cols, device)\n",
    "#         train_config[\"dataset\"] = f\"{dataset_name}_continuous_only\"\n",
    "#         train_config[\"device\"] = device\n",
    "\n",
    "#         criterion = nn.CrossEntropyLoss()\n",
    "#         optimizer = run_pytorch.build_optimizer(model, \"adam\", train_config[\"learning_rate\"])\n",
    "#         path = f\"models/train/{model_name}/{dataset_name}_continuous_only/train_run-test.pt\"\n",
    "#         model.load_state_dict(torch.load(path))\n",
    "        \n",
    "#         # run_pytorch.test(model, (X_test_tensor, y_test_tensor), train_config, stage=\"train\", wandb_run=wandb.run)\n",
    "\n",
    "#         ## LinfFGSM\n",
    "#         epsilons = np.arange(0.01, 0.15, 0.02)  # You can change the epsilon values\n",
    "#         attack_config = {**train_config, \"epsilons\": epsilons}\n",
    "#         attack_success_rates, average_distances, outliner_rates = attack_LinfFGSM(model, epsilons, X_test_tensor, y_test_tensor, X_train_tensor, len(info.numerical_cols), attack_config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zippo/miniconda3/envs/tabular-benchmark/lib/python3.10/site-packages/foolbox/models/pytorch.py:36: UserWarning: The PyTorch model is in training mode and therefore might not be deterministic. Call the eval() method to set it in evaluation mode if this is not intended.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 6.429396406462071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [1:11:19<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon = 0.0\n",
      "Success Rate: 27.04%\n",
      "Average L0 Distance for Successful Attacks: 0.0\n",
      "Average L1 Distance for Successful Attacks: 0.0\n",
      "Average L2 Distance for Successful Attacks: 0.0\n",
      "Average Linf Distance for Successful Attacks: 0.0\n",
      "Average Mahalanobis Distance for Successful Attacks: 5.055094793359479\n",
      "Average Sensitivity for Successful Attacks: 0.0\n",
      "Outlier Rate for Successful Attacks: 9.245562130177515%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [1:10:31<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon = 0.01\n",
      "Success Rate: 43.2%\n",
      "Average L0 Distance for Successful Attacks: 27.283333333333335\n",
      "Average L1 Distance for Successful Attacks: 0.0016233369656506343\n",
      "Average L2 Distance for Successful Attacks: 0.0037420050027832386\n",
      "Average Linf Distance for Successful Attacks: 0.016094493369657223\n",
      "Average Mahalanobis Distance for Successful Attacks: 4.948732484808444\n",
      "Average Sensitivity for Successful Attacks: 0.0009305887459270363\n",
      "Outlier Rate for Successful Attacks: 7.3842592592592595%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [1:10:20<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon = 0.03\n",
      "Success Rate: 75.99000000000001%\n",
      "Average L0 Distance for Successful Attacks: 27.603237268061587\n",
      "Average L1 Distance for Successful Attacks: 0.00828212762041994\n",
      "Average L2 Distance for Successful Attacks: 0.0193256296570283\n",
      "Average Linf Distance for Successful Attacks: 0.08348450285188999\n",
      "Average Mahalanobis Distance for Successful Attacks: 4.979920354151647\n",
      "Average Sensitivity for Successful Attacks: 0.004739180022638221\n",
      "Outlier Rate for Successful Attacks: 6.921963416238978%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [1:10:21<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon = 0.05\n",
      "Success Rate: 89.81%\n",
      "Average L0 Distance for Successful Attacks: 27.664291281594476\n",
      "Average L1 Distance for Successful Attacks: 0.015072536683711365\n",
      "Average L2 Distance for Successful Attacks: 0.03494417679076814\n",
      "Average Linf Distance for Successful Attacks: 0.1505374385539698\n",
      "Average Mahalanobis Distance for Successful Attacks: 5.2009979671925874\n",
      "Average Sensitivity for Successful Attacks: 0.008624767936997279\n",
      "Outlier Rate for Successful Attacks: 9.00790557844338%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [1:10:25<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon = 0.1\n",
      "Success Rate: 97.57000000000001%\n",
      "Average L0 Distance for Successful Attacks: 27.690991083324793\n",
      "Average L1 Distance for Successful Attacks: 0.0255680037529791\n",
      "Average L2 Distance for Successful Attacks: 0.057843690621353645\n",
      "Average Linf Distance for Successful Attacks: 0.2463399785379454\n",
      "Average Mahalanobis Distance for Successful Attacks: 5.683239766547783\n",
      "Average Sensitivity for Successful Attacks: 0.014630454016896251\n",
      "Outlier Rate for Successful Attacks: 20.108639950804548%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [1:10:13<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon = 0.3\n",
      "Success Rate: 99.86%\n",
      "Average L0 Distance for Successful Attacks: 27.698077308231525\n",
      "Average L1 Distance for Successful Attacks: 0.027850123452865947\n",
      "Average L2 Distance for Successful Attacks: 0.06237023360772598\n",
      "Average Linf Distance for Successful Attacks: 0.2633681312136478\n",
      "Average Mahalanobis Distance for Successful Attacks: 5.8033625408901095\n",
      "Average Sensitivity for Successful Attacks: 0.01593632198420887\n",
      "Outlier Rate for Successful Attacks: 22.291207690767074%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [1:10:18<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon = 0.5\n",
      "Success Rate: 99.88%\n",
      "Average L0 Distance for Successful Attacks: 27.698137765318382\n",
      "Average L1 Distance for Successful Attacks: 0.02790282573999313\n",
      "Average L2 Distance for Successful Attacks: 0.06248478466262733\n",
      "Average Linf Distance for Successful Attacks: 0.26378822587164136\n",
      "Average Mahalanobis Distance for Successful Attacks: 5.807682922758364\n",
      "Average Sensitivity for Successful Attacks: 0.0159664791346352\n",
      "Outlier Rate for Successful Attacks: 22.3167801361634%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [1:10:02<00:00,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon = 1.0\n",
      "Success Rate: 99.88%\n",
      "Average L0 Distance for Successful Attacks: 27.698137765318382\n",
      "Average L1 Distance for Successful Attacks: 0.027903261003687393\n",
      "Average L2 Distance for Successful Attacks: 0.06248572122776106\n",
      "Average Linf Distance for Successful Attacks: 0.26379182164059317\n",
      "Average Mahalanobis Distance for Successful Attacks: 5.807720216603635\n",
      "Average Sensitivity for Successful Attacks: 0.015966728199458425\n",
      "Outlier Rate for Successful Attacks: 22.3167801361634%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "for dataset_name in [\"Higgs\"]: # \"Adult\", \"Electricity\", \"Higgs\", \"KDDCup09_appetency\", \"Mushroom\"\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, \\\n",
    "        X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor, X_val_tensor, y_val_tensor, \\\n",
    "        info = get_datasets.get_split(dataset_name, device)\n",
    "    # Considering size of Higgs dataset, we will use only 10k samples for adversarial attack.\n",
    "    if dataset_name == \"Higgs\":\n",
    "        X_test = X_test[:10000]\n",
    "        y_test = y_test[:10000]\n",
    "        X_test_tensor = X_test_tensor[:10000]\n",
    "        y_test_tensor = y_test_tensor[:10000]\n",
    "\n",
    "    for model_name in [\"FTTransformer\"]: # \"LogisticRegression\", \"MLP\", \"TabTransformer\", \"FTTransformer\"\n",
    "        model, train_config = run_pytorch.model_config(model_name, X_train.shape[1], 2, info.num_categories_list, info.numerical_cols, device)\n",
    "        train_config[\"dataset\"] = dataset_name\n",
    "        train_config[\"device\"] = device\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = run_pytorch.build_optimizer(model, \"adam\", train_config[\"learning_rate\"])\n",
    "        path = f\"models/train/{model_name}/{dataset_name}/train_run-test.pt\"\n",
    "        model.load_state_dict(torch.load(path))\n",
    "        \n",
    "        # run_pytorch.test(model, (X_test_tensor, y_test_tensor), train_config, stage=\"train\", wandb_run=wandb.run)\n",
    "\n",
    "        for attack_name in [\"L2CarliniWagner\"]: # \"LinfFGSM\", \"LinfPGD\", \"LinfBIM\", \"L2CarliniWagner\", \"L2DeepFool\", \"L2Gaussian\", \"L2Uniform\", \"LinfUniform\"\n",
    "\n",
    "            epsilons = [\n",
    "                0.0,\n",
    "                0.01,\n",
    "                0.03,\n",
    "                0.05,\n",
    "                0.1,\n",
    "                0.3,\n",
    "                0.5,\n",
    "                1.0,\n",
    "            ]\n",
    "            attack_config = {**train_config, \"epsilons\": epsilons}\n",
    "            attack_success_rates, average_distances, outliner_rates, path_sets = run_attack(model, attack_name, epsilons, X_test_tensor, y_test_tensor, X_train_tensor, len(info.numerical_cols), attack_config, device)\n",
    "\n",
    "            \n",
    "            results = {\n",
    "                \"model\": model_name,\n",
    "                \"dataset\": dataset_name,\n",
    "                \"attack\": attack_name,\n",
    "                \"attack_config\": attack_config,\n",
    "                \"result\": {\n",
    "                    \"epsilons\": epsilons,\n",
    "                    \"attack_success_rates\": attack_success_rates,\n",
    "                    \"average_distances\": average_distances,\n",
    "                    \"outliner_rates\": outliner_rates,\n",
    "                    \"numpy_path\": path_sets,\n",
    "                }\n",
    "            }\n",
    "\n",
    "            # save python dictionary\n",
    "            with open(f'results/{dataset_name}_{model_name}_{attack_name}.pickle', 'wb') as handle:\n",
    "                pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering size of Higgs dataset, we will use only 10k samples for adversarial attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabular-benchmark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
